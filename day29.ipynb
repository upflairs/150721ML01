{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',names=['type','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5568 entries, 0 to 5567\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    5568 non-null   object\n",
      " 1   text    5568 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4822</td>\n",
       "      <td>4513</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>746</td>\n",
       "      <td>652</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text                                                               \n",
       "     count unique                                                top freq\n",
       "type                                                                     \n",
       "ham   4822   4513                             Sorry, I'll call later   30\n",
       "spam   746    652  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg0 = df['text'][df['text'].str.len()==df['text'].str.len().max()].values[0]\n",
    "msg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'me', 'the', 'love', 'should', 'start', 'with', 'attraction', '.']\n",
      "['i', 'should', 'feel', 'that', 'I', 'need', 'her', 'every', 'time', 'around', 'me', '.']\n",
      "['she', 'should', 'be', 'the', 'first', 'thing', 'which', 'comes', 'in', 'my', 'thoughts', '.']\n",
      "['I', 'would', 'start', 'the', 'day', 'and', 'end', 'it', 'with', 'her', '.']\n",
      "['she', 'should', 'be', 'there', 'every', 'time', 'I', 'dream', '.']\n",
      "['love', 'will', 'be', 'then', 'when', 'my', 'every', 'breath', 'has', 'her', 'name', '.']\n",
      "['my', 'life', 'should', 'happen', 'around', 'her', '.']\n",
      "['my', 'life', 'will', 'be', 'named', 'to', 'her', '.']\n",
      "['I', 'would', 'cry', 'for', 'her', '.']\n",
      "['will', 'give', 'all', 'my', 'happiness', 'and', 'take', 'all', 'her', 'sorrows', '.']\n",
      "['I', 'will', 'be', 'ready', 'to', 'fight', 'with', 'anyone', 'for', 'her', '.']\n",
      "['I', 'will', 'be', 'in', 'love', 'when', 'I', 'will', 'be', 'doing', 'the', 'craziest', 'things', 'for', 'her', '.']\n",
      "['love', 'will', 'be', 'when', 'I', 'do', \"n't\", 'have', 'to', 'proove', 'anyone', 'that', 'my', 'girl', 'is', 'the', 'most', 'beautiful', 'lady', 'on', 'the', 'whole', 'planet', '.']\n",
      "['I', 'will', 'always', 'be', 'singing', 'praises', 'for', 'her', '.']\n",
      "['love', 'will', 'be', 'when', 'I', 'start', 'up', 'making', 'chicken', 'curry', 'and', 'end', 'up', 'makiing', 'sambar', '.']\n",
      "['life', 'will', 'be', 'the', 'most', 'beautiful', 'then', '.']\n",
      "['will', 'get', 'every', 'morning', 'and', 'thank', 'god', 'for', 'the', 'day', 'because', 'she', 'is', 'with', 'me', '.']\n",
      "['I', 'would', 'like', 'to', 'say', 'a', 'lot', '.']\n",
      "['.']\n",
      "['will', 'tell', 'later', '.']\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "for s in nltk.sent_tokenize(msg0.replace('.','. ')):\n",
    "    words = nltk.word_tokenize(s)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation as punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(t):\n",
    "    words = []\n",
    "    for sent in nltk.sent_tokenize(t.lower()):\n",
    "        ws = nltk.word_tokenize(sent)\n",
    "        words += [w for w in ws if w.isalpha() and w not in sw]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love start feel need every time around first thing comes would start day end every time every breath life happen around life named would cry give happiness take ready fight anyone love craziest things proove anyone girl beautiful lady whole always singing praises start making chicken curry end makiing beautiful get every morning thank god day would like say lot tell later'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text(msg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "word_list.append(process_text(msg0))\n",
    "word_list.append(process_text(df['text'][1003]))\n",
    "word_list.append(process_text(df['text'][4005]))\n",
    "word_list.append(process_text(df['text'][619]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love start feel need every time around first thing comes would start day end every time every breath life happen around life named would cry give happiness take ready fight anyone love craziest things proove anyone girl beautiful lady whole always singing praises start making chicken curry end makiing beautiful get every morning thank god day would like say lot tell later',\n",
       " 'panasonic bluetoothhdset free nokia free motorola free doublemins doubletxt orange contract call call',\n",
       " 'forgot working today wan na chat things ok drop text free bored etc ring hope well nose essay xx',\n",
       " 'make sure alex knows birthday fifteen minutes far concerned']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x83 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 85 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alex',\n",
       " 'always',\n",
       " 'anyone',\n",
       " 'around',\n",
       " 'beautiful',\n",
       " 'birthday',\n",
       " 'bluetoothhdset',\n",
       " 'bored',\n",
       " 'breath',\n",
       " 'call',\n",
       " 'chat',\n",
       " 'chicken',\n",
       " 'comes',\n",
       " 'concerned',\n",
       " 'contract',\n",
       " 'craziest',\n",
       " 'cry',\n",
       " 'curry',\n",
       " 'day',\n",
       " 'doublemins',\n",
       " 'doubletxt',\n",
       " 'drop',\n",
       " 'end',\n",
       " 'essay',\n",
       " 'etc',\n",
       " 'every',\n",
       " 'far',\n",
       " 'feel',\n",
       " 'fifteen',\n",
       " 'fight',\n",
       " 'first',\n",
       " 'forgot',\n",
       " 'free',\n",
       " 'get',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'god',\n",
       " 'happen',\n",
       " 'happiness',\n",
       " 'hope',\n",
       " 'knows',\n",
       " 'lady',\n",
       " 'later',\n",
       " 'life',\n",
       " 'like',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'make',\n",
       " 'makiing',\n",
       " 'making',\n",
       " 'minutes',\n",
       " 'morning',\n",
       " 'motorola',\n",
       " 'na',\n",
       " 'named',\n",
       " 'need',\n",
       " 'nokia',\n",
       " 'nose',\n",
       " 'ok',\n",
       " 'orange',\n",
       " 'panasonic',\n",
       " 'praises',\n",
       " 'proove',\n",
       " 'ready',\n",
       " 'ring',\n",
       " 'say',\n",
       " 'singing',\n",
       " 'start',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'tell',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'time',\n",
       " 'today',\n",
       " 'wan',\n",
       " 'well',\n",
       " 'whole',\n",
       " 'working',\n",
       " 'would',\n",
       " 'xx']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniword = cv.get_feature_names()\n",
    "uniword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex</th>\n",
       "      <th>always</th>\n",
       "      <th>anyone</th>\n",
       "      <th>around</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>birthday</th>\n",
       "      <th>bluetoothhdset</th>\n",
       "      <th>bored</th>\n",
       "      <th>breath</th>\n",
       "      <th>call</th>\n",
       "      <th>...</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>wan</th>\n",
       "      <th>well</th>\n",
       "      <th>whole</th>\n",
       "      <th>working</th>\n",
       "      <th>would</th>\n",
       "      <th>xx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alex  always  anyone  around  beautiful  birthday  bluetoothhdset  bored  \\\n",
       "0     0       1       2       2          2         0               0      0   \n",
       "1     0       0       0       0          0         0               1      0   \n",
       "2     0       0       0       0          0         0               0      1   \n",
       "3     1       0       0       0          0         1               0      0   \n",
       "\n",
       "   breath  call  ...  thing  things  time  today  wan  well  whole  working  \\\n",
       "0       1     0  ...      1       1     2      0    0     0      1        0   \n",
       "1       0     2  ...      0       0     0      0    0     0      0        0   \n",
       "2       0     0  ...      0       1     0      1    1     1      0        1   \n",
       "3       0     0  ...      0       0     0      0    0     0      0        0   \n",
       "\n",
       "   would  xx  \n",
       "0      3   0  \n",
       "1      0   0  \n",
       "2      0   1  \n",
       "3      0   0  \n",
       "\n",
       "[4 rows x 83 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df = pd.DataFrame(bow.toarray(),columns=uniword)\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfV = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tfidfV.fit_transform(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x83 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqword = tfidfV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alex</th>\n",
       "      <th>always</th>\n",
       "      <th>anyone</th>\n",
       "      <th>around</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>birthday</th>\n",
       "      <th>bluetoothhdset</th>\n",
       "      <th>bored</th>\n",
       "      <th>breath</th>\n",
       "      <th>call</th>\n",
       "      <th>...</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>wan</th>\n",
       "      <th>well</th>\n",
       "      <th>whole</th>\n",
       "      <th>working</th>\n",
       "      <th>would</th>\n",
       "      <th>xx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>0.198398</td>\n",
       "      <td>0.198398</td>\n",
       "      <td>0.198398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.198398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297597</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alex    always    anyone    around  beautiful  birthday  \\\n",
       "0  0.000000  0.099199  0.198398  0.198398   0.198398  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "3  0.333333  0.000000  0.000000  0.000000   0.000000  0.333333   \n",
       "\n",
       "   bluetoothhdset     bored    breath      call  ...     thing    things  \\\n",
       "0        0.000000  0.000000  0.099199  0.000000  ...  0.099199  0.078210   \n",
       "1        0.238404  0.000000  0.000000  0.476808  ...  0.000000  0.000000   \n",
       "2        0.000000  0.234126  0.000000  0.000000  ...  0.000000  0.184588   \n",
       "3        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "       time     today       wan      well     whole   working     would  \\\n",
       "0  0.198398  0.000000  0.000000  0.000000  0.099199  0.000000  0.297597   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.234126  0.234126  0.234126  0.000000  0.234126  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         xx  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.234126  \n",
       "3  0.000000  \n",
       "\n",
       "[4 rows x 83 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tf_idf.toarray(),columns=uniqword)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial: 97.93\n",
      "Gaussain: 92.98\n",
      "Bernoulli: 98.4\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "for _,m in df.iterrows():\n",
    "    word_list.append(process_text(m['text']))\n",
    "\n",
    "tfidfV = TfidfVectorizer()\n",
    "tf_idf = tfidfV.fit_transform(word_list)\n",
    "uniqword = tfidfV.get_feature_names()\n",
    "x = pd.DataFrame(tf_idf.toarray(),columns=uniqword)\n",
    "y = df['type']\n",
    "\n",
    "model_mnb = MultinomialNB().fit(x,y)\n",
    "model_gnb = GaussianNB().fit(x,y)\n",
    "model_bnb = BernoulliNB().fit(x,y)\n",
    "\n",
    "print('Multinomial:',round(model_mnb.score(x,y)*100,2))\n",
    "print('Gaussain:',round(model_gnb.score(x,y)*100,2))\n",
    "print('Bernoulli:',round(model_bnb.score(x,y)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
